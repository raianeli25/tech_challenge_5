## Datathon - Tech Challenge #5 **ğŸ§©**

Grupo:
* Chrystian Remes
* Raiane Lima
* Thales Mendes

<br>

ğŸ¯Objetivo: ConstruÃ§Ã£o de um sistema de recomendaÃ§Ã£o de notÃ­cias baseado em dados do G1 (Globo).

### **Tecnologias utilizadas ğŸ’¡**

NÃ³s utilizamos 4 containers em Docker para construÃ§Ã£o da soluÃ§Ã£o:

* api: API de ingestÃ£o dos dados (CSV -> Mongo DB) e para recomendaÃ§Ã£o de conteÃºdo.
* app: aplicaÃ§Ã£o web streamlit que consulta a API e mostra as recomendaÃ§Ãµes em interface amigÃ¡vel.
* mongo: utilizamos o Mongo DB para salvar os dados das notÃ­cias.
* mongo-express: interface grÃ¡fica do mongo db onde podemos fazer consultas.

<br>

A imagem abaixo traz a visÃ£o dos containers de forma mais detalhada.

<img src="docs/containers.png" alt="containers" width="500"/>

<br>

A arquitetura da nossa soluÃ§Ã£o pode ser vista na imagem abaixo.

<img src="docs/arquitetura.png" alt="architeture" width="800"/>

<br>

Inicialmente, Ã© preciso ingestar os dados no mongo atravÃ©s do endpoint da api, como mostrado na imagem acima. ApÃ³s isso, a soluÃ§Ã£o jÃ¡ estarÃ¡ pronta para ser colocada em produÃ§Ã£o.

**Passo a passo**

**01**: UsuÃ¡rio passa o hash via interface grÃ¡fica, na prÃ¡tica terÃ­amos a pÃ¡gina do G1 e isso seria passado de maneira automatizada para a API.

**02**: UI envia o dado do usuÃ¡rio para API no endpoint de recomendaÃ§Ã£o.

**03**: API utiliza os artefatos do modelo e realiza o predict com as informaÃ§Ãµes passadas via UI. Com a lista de recomendaÃ§Ãµes, API consulta o banco atravÃ©s de uma funÃ§Ã£o para recuperar os tÃ­tulos das notÃ­cias a partir do _id (hash da notÃ­cia).

**04**: Banco retorna os tÃ­tulos de acordo com o _id passado.

**05**: API retorna lista com as recomendaÃ§Ãµes para a UI.

**06**: UI retorna a informaÃ§Ã£o das notÃ­cias recomendadas de maneira amigÃ¡vel para o usuÃ¡rio.

### Estrutura de pastas **ğŸ“‚**

---

<br>

```
tech_challenge_5
â”œâ”€â”€ .github/workflows
â”‚   â”œâ”€â”€ cd.yml
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ api
â”‚   â”œâ”€â”€ artifacts
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ utils
|   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ app.py
|   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ arquitetura.png
â”‚   â”œâ”€â”€ containers.png
â”‚   â”œâ”€â”€ diagramas.drawio
â”‚   â””â”€â”€ deploy.png
â”œâ”€â”€ recommendation
â”‚   â”œâ”€â”€ artifacts
â”‚   â”œâ”€â”€ devs_others
â”‚   â”œâ”€â”€ utils
â”‚   â”œâ”€â”€ 1_a_treating_train_data.ipynb
|   ... 
â”‚   â”œâ”€â”€ 4_validating_model.ipynb
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ tests
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ requirements.txt
```
<br>

* **.github/workflows**: ContÃ©m as pipelines de ci/cd que sÃ£o executadas no github.
* **api**: ContÃ©m todos os cÃ³digos relacionados a API.
* **app**: Armazena os arquivos relativos Ã  aplicaÃ§Ã£o (streamlit).
* **docs**: ContÃ©m diagramas, imagens e demais arquivos para documentaÃ§Ã£o
* **recommendation**: Possui todos os jupyter notebooks utilizados para as anÃ¡lises, treinamento e validaÃ§Ã£o do modelo.
* **tests**: Pasta contendo todos os testes da API.
* **docker-compose.yml**: Arquivo responsÃ¡vel por orquestrar toda a criaÃ§Ã£o dos containers da aplicaÃ§Ã£o.
* **requirements.txt**: Arquivo com as dependÃªncias necessÃ¡rias para rodar os testes na pipeline de CI.
  
<br>

### InÃ­cio rÃ¡pido (local) ğŸš€

---

1. Certifique-se de que vocÃª possui uma instalaÃ§Ã£o Docker funcionando.
2. VÃ¡ na raiz do projeto (ou seja, na raÃ­z de `tech_challenge_5`) e rode o comando `docker compose up --build -d`. A criaÃ§Ã£o dos containers demora em torno de 5 minutos, mas pode variar dependendo das configuraÃ§Ãµes do seu computador.
3. Certifique-se de que os containers estÃ£o com state `running`.
4. Crie uma pasta chamada `data` na raÃ­z do repo e copie o .csv com a base das notÃ­cias.
5. Acesse a API para caregamento da base de notÃ­cias no mongo, no endereÃ§o `http://localhost/8000/docs`. No endpoint /post_data_into_db digite o caminho a seguir: `/app/data/nome_arquivo.csv`
6. VocÃª tambÃ©m pode acessar a interface grÃ¡fica do mongo no endereÃ§o `http://localhost/8081/`, para conferir se o dataset foi ingestado. (login: root e senha: root)
7. Acesse a aplicaÃ§Ã£o no endereÃ§o `http://localhost/8501/`. Insira o hash de um usuÃ¡rio e a interface irÃ¡ lhe fornecer as recomendaÃ§Ãµes.

<br>

### Deploy em nuvem âš™ï¸

Diagrama explicativo do workflow de CI/CD para deploy em nuvem.
<!-- ![architeture](docs/architeture.png) -->
<img src="docs/deploy.png" alt="architeture" width="800"/>

<br>

Na abertura do PR a pipeline de CI executa e roda o pytest para garantir que o cÃ³digo nÃ£o irÃ¡ subir quebrado para produÃ§Ã£o. Ao realizar o merge para a branch main a pipeline de CD Ã© executada, criando uma instÃ¢ncia EC2 e realizando o deploy do cÃ³digo nessa instÃ¢ncia. Ao final da execuÃ§Ã£o desta pipeline, Ã© fornecido o link para acesso a interface do streamlit.

<br>

### Desenvolvimentos futuros âš’ï¸

- Aprofundamento da exploraÃ§Ã£o dos dados para encontrar novas possÃ­veis features (feature engineering). E.g. ter features de usuÃ¡rios e ou de notÃ­cias (tags) que poderiam ser usadas para clusterizar os users/items, melhorando a performance no cold-start.

- ReorganizaÃ§Ã£o do tratamento dos dados: algumas das etapas (limpezas dos "histories" que nÃ£o estÃ£o no formato de hash) poderiam ser feitas em etapas anteriores.

- Aprofundar o conhecimento no uso da Lib LightFM, visando um melhor tuning dos hyper-parÃ¢metros.

- Pipeline para retreino de modelo periodicamente, conforme novas notÃ­cias e usuÃ¡rios vÃ£o chegando a base (tambÃ©m atuando na melhora nos cenÃ¡rios de cold-start).
  
- Carregar os dados via bucket, dessa forma podemos integrar automaticamente as novas notÃ­cias no Mongo DB utilizando uma lambda function, por exemplo;
  
- UtilizaÃ§Ã£o de serviÃ§os de cloud mais robustos como ECS ou EKS, por questÃµes de custo e tempo nÃ£o avanÃ§amos mais na infraestrutura.

<br>

### Demo âš’ï¸

---

Clique [aqui]() e assita a demo.

