{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model recommendation with lighfm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import itertools\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import scipy\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from lightfm import LightFM\n",
                "from lightfm.data import Dataset\n",
                "from lightfm.evaluation import precision_at_k, recall_at_k\n",
                "from lightfm.cross_validation import random_train_test_split\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from lightfm import cross_validation\n",
                "import scipy.sparse as sp\n",
                "from scipy import sparse"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lightfm import LightFM\n",
                "from sklearn.base import clone\n",
                "\n",
                "\n",
                "class LightFMResizable(LightFM):\n",
                "    \"\"\"A LightFM that resizes the model to accomodate new users,\n",
                "    items, and features\"\"\"\n",
                "\n",
                "    def fit_partial(\n",
                "        self,\n",
                "        interactions,\n",
                "        user_features=None,\n",
                "        item_features=None,\n",
                "        sample_weight=None,\n",
                "        epochs=1,\n",
                "        num_threads=1,\n",
                "        verbose=False,\n",
                "    ):\n",
                "        try:\n",
                "            self._check_initialized()\n",
                "            self._resize(interactions, user_features, item_features)\n",
                "        except ValueError:\n",
                "            # This is the first call so just fit without resizing\n",
                "            pass\n",
                "\n",
                "        super().fit_partial(\n",
                "            interactions,\n",
                "            user_features,\n",
                "            item_features,\n",
                "            sample_weight,\n",
                "            epochs,\n",
                "            num_threads,\n",
                "            verbose,\n",
                "        )\n",
                "\n",
                "        return self\n",
                "\n",
                "    def _resize(self, interactions, user_features=None, item_features=None):\n",
                "        \"\"\"Resizes the model to accommodate new users/items/features\"\"\"\n",
                "\n",
                "        no_components = self.no_components\n",
                "        no_user_features, no_item_features = interactions.shape  # default\n",
                "\n",
                "        if hasattr(user_features, \"shape\"):\n",
                "            no_user_features = user_features.shape[-1]\n",
                "        if hasattr(item_features, \"shape\"):\n",
                "            no_item_features = item_features.shape[-1]\n",
                "\n",
                "        if (\n",
                "            no_user_features == self.user_embeddings.shape[0]\n",
                "            and no_item_features == self.item_embeddings.shape[0]\n",
                "        ):\n",
                "            return self\n",
                "\n",
                "        new_model = clone(self)\n",
                "        new_model._initialize(no_components, no_item_features, no_user_features)\n",
                "\n",
                "        # update all attributes from self._check_initialized\n",
                "        for attr in (\n",
                "            \"item_embeddings\",\n",
                "            \"item_embedding_gradients\",\n",
                "            \"item_embedding_momentum\",\n",
                "            \"item_biases\",\n",
                "            \"item_bias_gradients\",\n",
                "            \"item_bias_momentum\",\n",
                "            \"user_embeddings\",\n",
                "            \"user_embedding_gradients\",\n",
                "            \"user_embedding_momentum\",\n",
                "            \"user_biases\",\n",
                "            \"user_bias_gradients\",\n",
                "            \"user_bias_momentum\",\n",
                "        ):\n",
                "            # extend attribute matrices with new rows/cols from\n",
                "            # freshly initialized model with right shape\n",
                "            old_array = getattr(self, attr)\n",
                "            old_slice = [slice(None, i) for i in old_array.shape]\n",
                "            new_array = getattr(new_model, attr)\n",
                "            new_array[tuple(old_slice)] = old_array\n",
                "            setattr(self, attr, new_array)\n",
                "\n",
                "        return self"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Defining variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "with open('config.json', 'r') as f:\n",
                "    config = json.load(f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# NUM_ITEMS_TRAIN = 108573\n",
                "NUM_ITEMS_TRAIN = 63893\n",
                "# NUM_ITEMS_TRAIN = 231305\n",
                "\n",
                "NO_EPOCHS = 80\n",
                "\n",
                "NUM_COMPONENTS = 30\n",
                "\n",
                "NUM_THREADS = 4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Retrieve data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dtype_df_valid = {\n",
                "\"userId\" : 'string',\n",
                "\"userType\" : 'category',\n",
                "\"history\" : 'string',\n",
                "\"timestampHistory\" : 'string'\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "# path config\n",
                "\n",
                "df_valid = pd.read_csv(config[\"VALID_DF\"],dtype=dtype_df_valid,nrows=10000)\n",
                "df_valid.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dtype_df_train_score = {\n",
                "\"userId\" : 'string',\n",
                "\"userType\" : 'category',\n",
                "\"history\" : 'string',\n",
                "\"score\" : 'Float32'\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# df_ratings = pd.read_csv(config[\"DF_TRAIN_SCORES\"], dtype=dtype_df_train_score)\n",
                "df_ratings = pd.read_csv(config[\"DF_TRAIN_SCORES\"], dtype=dtype_df_train_score, nrows=500010)\n",
                "df_ratings.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
                "df_ratings.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_news = pd.read_csv(config[\"DF_ITEMS_FEATURE\"])\n",
                "df_news.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
                "df_news.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_valid_new = df_valid.drop(columns=\"timestampHistory\")\n",
                "\n",
                "from utils.custom_treat_data_funcs import transform_text_to_list, explode_df_columns\n",
                "\n",
                "# df_valid_new[\"history\"] = df_valid_new[\"history\"].apply(str)\n",
                "df_valid_new[\"history\"] = df_valid_new[\"history\"].apply(transform_text_to_list)\n",
                "# df_valid_new.head(3)\n",
                "df_valid_new = df_valid_new.explode(\"history\", ignore_index=True)\n",
                "df_valid_new.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_valid_new.loc[0,\"history\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_valid_exploded = pd.concat([df_ratings, df_valid_new])\n",
                "df_valid_exploded"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# duplicates = df_valid_exploded[df_valid_exploded.duplicated(subset=['userId','history'], keep=False)]\n",
                "# duplicates = duplicates[duplicates[\"score\"].isna()]\n",
                "duplicates = df_valid_exploded[df_valid_exploded.duplicated(subset=['userId','history'], keep='first')]\n",
                "duplicates\n",
                "# duplicates = df_valid_exploded[df_valid_exploded.duplicated(subset=['history'], keep=False)]\n",
                "# duplicates[duplicates[\"history\"]=='253339a1-92b6-44d1-8fa2-59236c5251b1']\n",
                "# duplicates[duplicates[\"userId\"]=='f0e758359a184c99912e1ad5fc912b92b5e7b63c7a6002']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_valid_cleaned = df_valid_exploded.drop_duplicates(subset=['userId','history'], keep=\"first\")\n",
                "df_valid_cleaned"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_valid_cleaned[\"score\"].fillna(0,inplace=True)\n",
                "df_valid_cleaned"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_valid = Dataset()\n",
                "\n",
                "# Get unique values for users, items, and user features\n",
                "unique_users_valid = df_valid_cleaned[\"userId\"].unique()\n",
                "unique_items_valid = df_valid_cleaned[\"history\"].unique()\n",
                "unique_user_features_valid = df_valid_cleaned[\"userType\"].unique().tolist()\n",
                "\n",
                "# Fit dataset with users, items, and user feature names\n",
                "dataset_valid.fit_partial(\n",
                "    users=unique_users_valid,\n",
                "    items=unique_items_valid,\n",
                "    user_features=unique_user_features_valid  # Register user features\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(interactions_valid, weights_valid) = dataset_valid.build_interactions([\n",
                "    (row.userId, row.history, row.score) \n",
                "    for _, row in df_valid_cleaned.iterrows()\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(unique_users_valid.shape)\n",
                "print(unique_items_valid.shape)\n",
                "print(len(unique_user_features_valid))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "interactions_valid.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "user_features_list_valid = [\n",
                "    (row.userId, [row.userType])  \n",
                "    for _, row in df_valid.iterrows()\n",
                "]\n",
                "\n",
                "user_features_valid = dataset_valid.build_user_features(user_features_list_valid)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(user_features_valid)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "loaded_model = pickle.load(open('artifacts/lightfm_model.pkl', 'rb'))\n",
                "loaded_user_id_map = pickle.load(open('artifacts/user_id_map.pkl', 'rb'))\n",
                "loaded_item_id_map_reverse = pickle.load(open('artifacts/item_id_map_reverse.pkl', 'rb'))\n",
                "loaded_user_feature_map = pickle.load(open('artifacts/user_feature_map.pkl', 'rb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loaded_model.fit_partial(interactions=interactions_valid, sample_weight=weights_valid, user_features=user_features_valid,\n",
                "                         epochs=NO_EPOCHS, num_threads=NUM_THREADS)\n",
                "# loaded_model.fit_partial(interactions=interactions_valid, sample_weight=weights_valid,\n",
                "#                          epochs=NO_EPOCHS, num_threads=NUM_THREADS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "user_id_map, user_feature_map, item_id_map, item_feature_map = dataset_valid.mapping()\n",
                "item_id_map_reverse = {v: k for k, v in item_id_map.items()}\n",
                "\n",
                "loaded_user_id_map = user_id_map\n",
                "loaded_item_id_map_reverse = item_id_map_reverse\n",
                "loaded_user_feature_map = user_feature_map"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "# _, n_items = interactions.shape # no of users * no of items\n",
                "_, n_items_valid = interactions_valid.shape # no of users * no of items\n",
                "\n",
                "# n_items = NUM_ITEMS_TRAIN\n",
                "n_items = n_items_valid"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Make predictions to known and unknowm on same recommendation function with pkls"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_newuser_input(user_feature_map, user_feature_list):\n",
                "  normalised_val = 1.0 \n",
                "  target_indices = []\n",
                "  for feature in user_feature_list:\n",
                "    try:\n",
                "        target_indices.append(user_feature_map[feature])\n",
                "    except KeyError:\n",
                "        # print(\"new user feature encountered '{}'\".format(feature))\n",
                "        pass\n",
                "  #print(\"target indices: {}\".format(target_indices))\n",
                "  new_user_features = np.zeros(len(user_feature_map.keys()))\n",
                "  for i in target_indices:\n",
                "    new_user_features[i] = normalised_val\n",
                "  new_user_features = sparse.csr_matrix(new_user_features)\n",
                "  return(new_user_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample_recommendation_by_title(user_hash,df_news,user_feature_list,item_id_map_reverse,user_feature_map,user_id_map,model):\n",
                "    try:\n",
                "        user_x = user_id_map[user_hash]\n",
                "        scores = model.predict(user_x, np.arange(n_items)) # means predict for all\n",
                "    except:\n",
                "        new_user_features = format_newuser_input(user_feature_map, user_feature_list)\n",
                "        scores = model.predict(0, np.arange(n_items), user_features=new_user_features)\n",
                "    \n",
                "    top_5_indices = np.argsort(-scores)[:10]  # Sort scores in descending order and take the top 5\n",
                "    top_5_items = [item_id_map_reverse[i] for i in top_5_indices]\n",
                "\n",
                "    print(\"Top 5 recommended items:\")\n",
                "\n",
                "    for x in top_5_items:\n",
                "        row = df_news[df_news[\"page\"] == x]\n",
                "        print(\"        %s\" % row[\"title\"].values[0])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "# predict for known user\n",
                "# df_valid[\"userId\"].iloc[0]\n",
                "user_feature_list = [df_valid[\"userType\"].iloc[0]]\n",
                "user_hash = df_valid[\"userId\"].iloc[0]\n",
                "\n",
                "# sample_recommendation_by_title(user_hash,df_news,user_feature_list,loaded_item_id_map_reverse,loaded_user_feature_map,loaded_user_id_map,loaded_model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_recommended_history_list(user_hash,user_feature_list,item_id_map_reverse,user_feature_map,user_id_map,model):\n",
                "    \"\"\"\n",
                "    This function verifies if the users is known or new, and makes recommendations depending on this verification.\n",
                "    The top 5 recommendations from the list are returned.\n",
                "    \"\"\"\n",
                "    try:\n",
                "        user_x = user_id_map[user_hash]\n",
                "        scores = model.predict(user_x, np.arange(n_items)) # means predict for all\n",
                "    except:\n",
                "        new_user_features = format_newuser_input(user_feature_map, user_feature_list)\n",
                "        # scores = model.predict(0, np.arange(n_items))\n",
                "        scores = model.predict(0, np.arange(n_items), user_features=new_user_features)\n",
                "    \n",
                "    top_5_indices = np.argsort(-scores)[:20]  # Sort scores in descending order and take the top 5\n",
                "    top_5_items = [item_id_map_reverse[i] for i in top_5_indices]\n",
                "\n",
                "    return top_5_items"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'list' object has no attribute 'replace'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_treat_data_funcs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transform_text_to_list\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Transform the single string with histories/items into a list of strings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhistory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform_text_to_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_valid\n",
                        "File \u001b[0;32m~/Documents/GitRepos/TC5/tech_challenge_5/.venv/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/Documents/GitRepos/TC5/tech_challenge_5/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/Documents/GitRepos/TC5/tech_challenge_5/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
                        "File \u001b[0;32m~/Documents/GitRepos/TC5/tech_challenge_5/.venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/Documents/GitRepos/TC5/tech_challenge_5/.venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
                        "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
                        "File \u001b[0;32m~/Documents/GitRepos/TC5/tech_challenge_5/recommendation/utils/custom_treat_data_funcs.py:36\u001b[0m, in \u001b[0;36mtransform_text_to_list\u001b[0;34m(hist)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform_text_to_list\u001b[39m(hist:\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    This function substitutes potential breakers, such as \"\\n\" and \",\" by blank spaces.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Also, it removes leading/trailing spaces with strip.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Finally, the strings separated by spaces are split into elements of a list.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Example: the string \"76, 38, 41\" is converted into a list [\"76\", \"38\", \"41\"] \u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     37\u001b[0m         replace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     38\u001b[0m         replace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     39\u001b[0m         replace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     40\u001b[0m         replace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     41\u001b[0m         strip()\u001b[38;5;241m.\u001b[39msplit()\n",
                        "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
                    ]
                }
            ],
            "source": [
                "from utils.custom_treat_data_funcs import transform_text_to_list\n",
                "\n",
                "# Transform the single string with histories/items into a list of strings\n",
                "\n",
                "df_valid[\"history\"] = df_valid[\"history\"].apply(transform_text_to_list)\n",
                "df_valid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['d2593c3d-2347-40d9-948c-b6065e8459a9', 'f6b5d170-48b9-4f8e-88d4-c84b6668f3bd', '1f32787b-de2b-49be-8c20-ddaeae34cc22', '6a83890a-d9e9-4f6b-a6c6-90d031785bbf', 'f0a78e58-ec7e-494c-9462-fbd6446a9a89', '4c63d7cd-4902-4ffb-9b94-578b1b2151f0', '855d20b7-53f2-4678-a10f-55402d085018', 'bf257382-74fb-4392-ad6a-143240e39f81', '1c27cf97-b20c-4e40-b1f1-288b721517b3', 'a36c98b5-f159-48f8-9f5a-1fc6ea9956c8', '4e9c2825-ff13-41ca-8e91-edd848060d19', '882e7c95-935a-4eab-9ece-f85f5f7d0f4e', '15281e10-e6bc-48bc-9b1b-94402f83699b', '8c246d2b-81bd-4c1f-b563-2c905675f984', '89fa73f0-4341-4de4-bb2a-e429ef96bd43', '29b6b142-4173-4ec4-832f-7d0a32255c10', '7b056bf6-c232-46bd-8903-59145ff7ce46', '4700f517-5c5d-483c-81b7-d77aca04991c', 'e384ec29-136e-4241-9321-49b367b8cbd5', '458bf0ec-efb4-4bfd-9446-c80295e6aa87']\n",
                        "['be89a7da-d9fa-49d4-9fdc-388c27a15bc8', '01c59ff6-fb82-4258-918f-2910cb2d4c52']\n"
                    ]
                }
            ],
            "source": [
                "# Testing for just one user\n",
                "\n",
                "user_feature_list = [df_valid[\"userType\"].iloc[0]]\n",
                "user_hash = df_valid[\"userId\"].iloc[0]\n",
                "validation_history_hashes = df_valid[\"history\"].iloc[0]\n",
                "\n",
                "recommeded_histories = get_recommended_history_list(user_hash,user_feature_list,loaded_item_id_map_reverse,loaded_user_feature_map,loaded_user_id_map,loaded_model)\n",
                "print(recommeded_histories)\n",
                "print(validation_history_hashes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": [
                "def count_valid_recommendations(validation_history_hashes, recommeded_histories):\n",
                "    \"\"\"\n",
                "    This function receives \n",
                "    * The `validation_history_hashes` (which is a list of histories contained in the \"validacao.csv\")\n",
                "    * The `recommeded_histories` (which are the recommended histories/items by the model)\n",
                "    Then, it verifies how many recommended items match with the validation histories.\n",
                "    \"\"\"\n",
                "    count_valids = 0\n",
                "    for valid_hist in validation_history_hashes:\n",
                "        if valid_hist in recommeded_histories:\n",
                "            count_valids = count_valids+1\n",
                "    return count_valids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_valid[\"recommended_hists\"] = \"\" # creates a column to receive the list of recommended histories\n",
                "df_valid[\"matched_recommendations\"] = 0 # creates a column to receive the quantity of matches between recommendations and validation items\n",
                "df_valid[\"historySize\"] = df_valid[\"history\"].apply(lambda x : len(x)) # calculate the quantity of histories for each user"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>userId</th>\n",
                            "      <th>userType</th>\n",
                            "      <th>history</th>\n",
                            "      <th>timestampHistory</th>\n",
                            "      <th>recommended_hists</th>\n",
                            "      <th>matched_recommendations</th>\n",
                            "      <th>historySize</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4...</td>\n",
                            "      <td>Logged</td>\n",
                            "      <td>[be89a7da-d9fa-49d4-9fdc-388c27a15bc8, 01c59ff...</td>\n",
                            "      <td>[1660533136590 1660672113513]</td>\n",
                            "      <td></td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>d0afad7ea843d86597d822f0df1d39d31a3fea7c39fdee...</td>\n",
                            "      <td>Logged</td>\n",
                            "      <td>[77901133-aee7-4f7b-afc0-652231d76fe9]</td>\n",
                            "      <td>[1660556860253]</td>\n",
                            "      <td></td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              userId userType  \\\n",
                            "0  e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4...   Logged   \n",
                            "1  d0afad7ea843d86597d822f0df1d39d31a3fea7c39fdee...   Logged   \n",
                            "\n",
                            "                                             history  \\\n",
                            "0  [be89a7da-d9fa-49d4-9fdc-388c27a15bc8, 01c59ff...   \n",
                            "1             [77901133-aee7-4f7b-afc0-652231d76fe9]   \n",
                            "\n",
                            "                timestampHistory recommended_hists  matched_recommendations  \\\n",
                            "0  [1660533136590 1660672113513]                                          0   \n",
                            "1                [1660556860253]                                          0   \n",
                            "\n",
                            "   historySize  \n",
                            "0            2  \n",
                            "1            1  "
                        ]
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_valid.head(2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": [
                "import multiprocessing\n",
                "\n",
                "def parallelize_dataframe(df, func):\n",
                "    num_cores = multiprocessing.cpu_count()-1  #leave one free to not freeze machine\n",
                "    num_partitions = num_cores #number of partitions to split dataframe\n",
                "    df_split = np.array_split(df, num_partitions)\n",
                "    pool = multiprocessing.Pool(num_cores)\n",
                "    df = pd.concat(pool.map(func, df_split))\n",
                "    pool.close()\n",
                "    pool.join()\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def validate_recommendations(df_valid):\n",
                "for _, row in df_valid.iterrows():\n",
                "    \"\"\"\n",
                "    For each user, get the top 5 recommendations from the model, and also count how many of them are contained within the validation set.\n",
                "    Stores the results on the columns `recommended_hists` `matched_recommendations`.\n",
                "    \"\"\"\n",
                "    user_feature_list = [row[\"userType\"]]\n",
                "    user_hash = row[\"userId\"]\n",
                "    validation_history_hashes = row[\"history\"]\n",
                "\n",
                "    recommended_hist = get_recommended_history_list(user_hash,user_feature_list,loaded_item_id_map_reverse,loaded_user_feature_map,loaded_user_id_map,loaded_model)\n",
                "    num_valid_recommendations = count_valid_recommendations(validation_history_hashes, recommended_hist)\n",
                "\n",
                "    row[\"recommended_hists\"] = recommended_hist\n",
                "    row[\"matched_recommendations\"] = num_valid_recommendations\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>userId</th>\n",
                            "      <th>userType</th>\n",
                            "      <th>history</th>\n",
                            "      <th>timestampHistory</th>\n",
                            "      <th>recommended_hists</th>\n",
                            "      <th>matched_recommendations</th>\n",
                            "      <th>historySize</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4...</td>\n",
                            "      <td>Logged</td>\n",
                            "      <td>[be89a7da-d9fa-49d4-9fdc-388c27a15bc8, 01c59ff...</td>\n",
                            "      <td>[1660533136590 1660672113513]</td>\n",
                            "      <td></td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>d0afad7ea843d86597d822f0df1d39d31a3fea7c39fdee...</td>\n",
                            "      <td>Logged</td>\n",
                            "      <td>[77901133-aee7-4f7b-afc0-652231d76fe9]</td>\n",
                            "      <td>[1660556860253]</td>\n",
                            "      <td></td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              userId userType  \\\n",
                            "0  e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4...   Logged   \n",
                            "1  d0afad7ea843d86597d822f0df1d39d31a3fea7c39fdee...   Logged   \n",
                            "\n",
                            "                                             history  \\\n",
                            "0  [be89a7da-d9fa-49d4-9fdc-388c27a15bc8, 01c59ff...   \n",
                            "1             [77901133-aee7-4f7b-afc0-652231d76fe9]   \n",
                            "\n",
                            "                timestampHistory recommended_hists  matched_recommendations  \\\n",
                            "0  [1660533136590 1660672113513]                                          0   \n",
                            "1                [1660556860253]                                          0   \n",
                            "\n",
                            "   historySize  \n",
                            "0            2  \n",
                            "1            1  "
                        ]
                    },
                    "execution_count": 50,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_valid.head(2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>matched_recommendations</th>\n",
                            "      <th>historySize</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>10000.0</td>\n",
                            "      <td>10000.00000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.90410</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.23962</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.00000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.00000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.00000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2.00000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>5.00000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       matched_recommendations  historySize\n",
                            "count                  10000.0  10000.00000\n",
                            "mean                       0.0      1.90410\n",
                            "std                        0.0      1.23962\n",
                            "min                        0.0      1.00000\n",
                            "25%                        0.0      1.00000\n",
                            "50%                        0.0      1.00000\n",
                            "75%                        0.0      2.00000\n",
                            "max                        0.0      5.00000"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_valid.describe()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
