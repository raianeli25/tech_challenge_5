{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import itertools\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import scipy\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from lightfm import LightFM\n",
                "from lightfm.data import Dataset\n",
                "from lightfm.evaluation import precision_at_k, recall_at_k\n",
                "from lightfm.cross_validation import random_train_test_split\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from lightfm import cross_validation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Defining variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Select MovieLens data size\n",
                "MOVIELENS_DATA_SIZE = '100k'\n",
                "\n",
                "# default number of recommendations\n",
                "K = 10\n",
                "# percentage of data used for testing\n",
                "TEST_PERCENTAGE = 0.25\n",
                "# model learning rate\n",
                "LEARNING_RATE = 0.25\n",
                "# no of latent factors\n",
                "NO_COMPONENTS = 20\n",
                "# no of epochs to fit model\n",
                "NO_EPOCHS = 20\n",
                "# no of threads to fit model\n",
                "NO_THREADS = 32\n",
                "# regularisation for both user and item features\n",
                "ITEM_ALPHA = 1e-6\n",
                "USER_ALPHA = 1e-6\n",
                "\n",
                "# seed for pseudonumber generations\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Retrieve data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "# path config\n",
                "data_path = '/home/raiane/Documentos/Projetos/tech_challenge_5/data/training_data_v2.csv'\n",
                "df_ratings = pd.read_csv(\n",
                "    data_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 1426291 entries, 0 to 1426290\n",
                        "Data columns (total 7 columns):\n",
                        " #   Column                   Non-Null Count    Dtype  \n",
                        "---  ------                   --------------    -----  \n",
                        " 0   Unnamed: 0               1426291 non-null  int64  \n",
                        " 1   userId                   1426291 non-null  object \n",
                        " 2   history                  1426291 non-null  object \n",
                        " 3   numberOfClicksHistory    1426291 non-null  int64  \n",
                        " 4   timeOnPageHistory        1426291 non-null  int64  \n",
                        " 5   scrollPercentageHistory  1426291 non-null  float64\n",
                        " 6   pageVisitsCountHistory   1426291 non-null  int64  \n",
                        "dtypes: float64(1), int64(4), object(2)\n",
                        "memory usage: 76.2+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_ratings.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [],
            "source": [
                "#considerando apenas noticias com mais de 30 cliques\n",
                "clicks_counts = pd.DataFrame(df_ratings[\"history\"].value_counts())\n",
                "rare_news = clicks_counts[df_ratings[\"history\"].value_counts() <= 500].index\n",
                "common_news = df_ratings[~df_ratings[\"history\"].isin(rare_news)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [],
            "source": [
                "unique_historys = common_news.history.unique()\n",
                "unique_users = common_news.userId.unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "hash_dict = dict(enumerate(unique_historys.flatten(), 1))\n",
                "user_dict = dict(enumerate(unique_users.flatten(), 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "user_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hash_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [],
            "source": [
                "inv_map = {v: k for k, v in hash_dict.items()}\n",
                "inv_map_u = {v: k for k, v in user_dict.items()}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inv_map"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inv_map_u"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_211513/2843185100.py:1: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  common_news[\"history_number\"] = common_news[\"history\"].map(inv_map)\n",
                        "/tmp/ipykernel_211513/2843185100.py:2: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  common_news[\"user_number\"] = common_news[\"userId\"].map(inv_map_u)\n"
                    ]
                }
            ],
            "source": [
                "common_news[\"history_number\"] = common_news[\"history\"].map(inv_map)\n",
                "common_news[\"user_number\"] = common_news[\"userId\"].map(inv_map_u)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {},
            "outputs": [],
            "source": [
                "common_news = common_news[[\"user_number\",\"history_number\",\"numberOfClicksHistory\"]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>user_number</th>\n",
                            "      <th>history_number</th>\n",
                            "      <th>numberOfClicksHistory</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>80</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>33</th>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>16</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>64</th>\n",
                            "      <td>2</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>66</th>\n",
                            "      <td>2</td>\n",
                            "      <td>4</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>71</th>\n",
                            "      <td>2</td>\n",
                            "      <td>5</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    user_number  history_number  numberOfClicksHistory\n",
                            "4             1               1                     80\n",
                            "33            1               2                     16\n",
                            "64            2               3                      0\n",
                            "66            2               4                      0\n",
                            "71            2               5                      2"
                        ]
                    },
                    "execution_count": 91,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "common_news.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Prepare data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before fitting the LightFM model, we need to create an instance of `Dataset` which holds the interaction matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = Dataset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The `fit` method creates the user/item id mappings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Num users: 34107, num_topics: 536.\n"
                    ]
                }
            ],
            "source": [
                "dataset.fit(users=common_news['user_number'], \n",
                "            items=common_news['history_number'])\n",
                "\n",
                "# quick check to determine the number of unique users and items in the data\n",
                "num_users, num_topics = dataset.interactions_shape()\n",
                "print(f'Num users: {num_users}, num_topics: {num_topics}.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next is to build the interaction matrix. The `build_interactions` method returns 2 COO sparse matrices, namely the `interactions` and `weights` matrices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [],
            "source": [
                "(interactions, weights) = dataset.build_interactions(common_news.iloc[:, 0:3].values)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LightLM works slightly differently compared to other packages as it expects the train and test sets to have same dimension. Therefore the conventional train test split will not work.\n",
                "\n",
                "The package has included the `cross_validation.random_train_test_split` method to split the interaction data and splits it into two disjoint training and test sets. \n",
                "\n",
                "However, note that **it does not validate the interactions in the test set to guarantee all items and users have historical interactions in the training set**. Therefore this may result into a partial cold-start problem in the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_interactions, test_interactions = cross_validation.random_train_test_split(\n",
                "    interactions, test_percentage=TEST_PERCENTAGE,\n",
                "    random_state=np.random.RandomState(SEED))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Double check the size of both the train and test sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shape of train interactions: (34107, 536)\n",
                        "Shape of test interactions: (34107, 536)\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Shape of train interactions: {train_interactions.shape}\")\n",
                "print(f\"Shape of test interactions: {test_interactions.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Fit the LightFM model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this notebook, the LightFM model will be using the weighted Approximate-Rank Pairwise (WARP) as the loss. Further explanation on the topic can be found [here](https://making.lyst.com/lightfm/docs/examples/warp_loss.html#learning-to-rank-using-the-warp-loss).\n",
                "\n",
                "\n",
                "In general, it maximises the rank of positive examples by repeatedly sampling negative examples until a rank violation has been located. This approach is recommended when only positive interactions are present."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "model = LightFM(loss='warp', no_components=NO_COMPONENTS, \n",
                "                 learning_rate=LEARNING_RATE,                 \n",
                "                 random_state=np.random.RandomState(SEED))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The LightFM model can be fitted with the following code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.fit(interactions=train_interactions,\n",
                "          epochs=NO_EPOCHS);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Evaluate model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collaborative filtering train AUC: 0.8371181\n"
                    ]
                }
            ],
            "source": [
                "# Import the evaluation routines\n",
                "from lightfm.evaluation import auc_score\n",
                "\n",
                "# Compute and print the AUC score\n",
                "train_auc = auc_score(model, train_interactions, num_threads=2).mean()\n",
                "print('Collaborative filtering train AUC: %s' % train_auc)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collaborative filtering test AUC: 0.6553675\n"
                    ]
                }
            ],
            "source": [
                "test_auc = auc_score(model, test_interactions, train_interactions=train_interactions, num_threads=2).mean()\n",
                "print('Collaborative filtering test AUC: %s' % test_auc)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train precision_at_k: 0.13\n",
                        "Test  precision_at_k: 0.03\n",
                        "Train recall_at_k: 0.31\n",
                        "Test  recall_at_k: 0.07\n"
                    ]
                }
            ],
            "source": [
                "# Measure how well it did in the Test period\n",
                "for metric in [precision_at_k, recall_at_k]:\n",
                "    # Get the precision and recall for Train and Test\n",
                "    for data, name in [(train_interactions, \"Train\"), (test_interactions, \"Test \")]:\n",
                "        print(f\"{name} {metric.__name__}: %.2f\" % \n",
                "              metric(model,\n",
                "                         data, \n",
                "                         k=10).mean())\n",
                "        \n",
                "    # # What about for just new-to-user purchases?\n",
                "    # print(f\"Test new {metric.__name__}: %.2f\" % \n",
                "    #       metric(model,\n",
                "    #                  test_new_interactions, \n",
                "    #                  train_interactions=train_interactions, # supress previously bought prods from being recommended\n",
                "    #                  k=10).mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.5 Using validation csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_validacao = pd.read_csv(\n",
                "    '/home/raiane/Documentos/Projetos/tech_challenge_5/data/validacao.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(112184, 4)"
                        ]
                    },
                    "execution_count": 105,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_validacao.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_validacao[\"userid_number\"] = df_validacao[\"userId\"].map(inv_map_u)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.6 Make predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>0</th>\n",
                            "      <th>1</th>\n",
                            "      <th>2</th>\n",
                            "      <th>3</th>\n",
                            "      <th>4</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>-3.772773</td>\n",
                            "      <td>-1.512855</td>\n",
                            "      <td>-2.652201</td>\n",
                            "      <td>-2.191434</td>\n",
                            "      <td>-1.862019</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>-14.489299</td>\n",
                            "      <td>-13.110419</td>\n",
                            "      <td>-10.685356</td>\n",
                            "      <td>-11.419316</td>\n",
                            "      <td>-11.088422</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>-7.746505</td>\n",
                            "      <td>-6.028250</td>\n",
                            "      <td>-7.079825</td>\n",
                            "      <td>-6.130264</td>\n",
                            "      <td>-7.589519</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>-3.801059</td>\n",
                            "      <td>-1.944845</td>\n",
                            "      <td>1.787615</td>\n",
                            "      <td>1.890942</td>\n",
                            "      <td>1.018832</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>-3.299577</td>\n",
                            "      <td>-1.766210</td>\n",
                            "      <td>-1.637671</td>\n",
                            "      <td>-0.936435</td>\n",
                            "      <td>-1.748800</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           0          1          2          3          4\n",
                            "0  -3.772773  -1.512855  -2.652201  -2.191434  -1.862019\n",
                            "1 -14.489299 -13.110419 -10.685356 -11.419316 -11.088422\n",
                            "2  -7.746505  -6.028250  -7.079825  -6.130264  -7.589519\n",
                            "3  -3.801059  -1.944845   1.787615   1.890942   1.018832\n",
                            "4  -3.299577  -1.766210  -1.637671  -0.936435  -1.748800"
                        ]
                    },
                    "execution_count": 62,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Create all user and item matrix to get predictions for it\n",
                "n_users, n_items = train_interactions.shape\n",
                "\n",
                "# Force lightFM to create predictions for all users and all items\n",
                "scoring_user_ids = np.concatenate([np.full((n_items, ), i) for i in range(n_users)]) # repeat user ID for number of prods\n",
                "scoring_item_ids = np.concatenate([np.arange(n_items) for i in range(n_users)]) # repeat entire range of item IDs x number of user\n",
                "scores = model.predict(user_ids = scoring_user_ids, \n",
                "                                     item_ids = scoring_item_ids)\n",
                "scores = scores.reshape(-1, n_items) # get 1 row per user\n",
                "recommendations = pd.DataFrame(scores)\n",
                "recommendations.shape\n",
                "\n",
                "# Have a look at the predicted scores for the first 5 users and first 5 items\n",
                "recommendations.iloc[:5,:5] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_news = pd.read_csv(\"../data/noticias.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_news= df_news.drop(columns=[\"Unnamed: 0\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "User 26364\n",
                        "     Known positives:\n",
                        "        Delegado descarta participação de outra pessoa em morte de médica achada em banheiro de hospital, em Pirenópolis\n",
                        "        Ex-empresário proibiu Luva de Pedreiro de participar da festa de São João de Quijingue, diz prefeito da cidade \n",
                        "        Menino morre após passar 1 ano com prego no pulmão na Bahia; família acusa hospital de negligência\n",
                        "     Recommended:\n",
                        "        Casa abandonada em Higienópolis: Entenda o caso da mulher que vive em mansão de SP\n",
                        "5af379e6-1bd1-4cf8-a23c-03266fb77b2c\n",
                        "        Quem é Sabine Boghici, presa por golpe milionário contra a mãe e herdeira de um dos maiores colecionadores de arte do país\n",
                        "29b6b142-4173-4ec4-832f-7d0a32255c10\n",
                        "        Quem é Giovanni Quintella, anestesista preso em flagrante por estuprar grávida no parto; ele atuou em pelo menos 10 hospitais\n",
                        "8d477e04-3bab-4ad9-8fe3-799059238a9c\n",
                        "        Quem é Bolívar Guerrero Silva, médico preso por manter paciente em cárcere privado; ele responde a pelo menos 19 processos\n",
                        "05606e8a-4053-4683-ab95-3903bb2d4efd\n",
                        "        Jovem vai para a UTI após ser agredida e jogada em viela no litoral de SP\n",
                        "5ecc4b24-ff5d-4f8c-8449-53de3b34d213\n"
                    ]
                }
            ],
            "source": [
                "def sample_recommendation(model, train_interactions,df_news, user_ids):\n",
                "    \n",
                "\n",
                "    n_users, n_items = train_interactions.shape\n",
                "\n",
                "    for user_id in user_ids:\n",
                "\n",
                "        known_positives = np.vectorize(hash_dict.get)(train_interactions.tocsr()[user_id].indices)\n",
                "        \n",
                "        scores = model.predict(user_id, np.arange(n_items))\n",
                "        top_items = np.vectorize(hash_dict.get)(np.argsort(-scores))\n",
                "        \n",
                "        print(\"User %s\" % user_id)\n",
                "\n",
                "        print(\"     Known positives:\")\n",
                "        \n",
                "        for x in known_positives[:3]:\n",
                "            row = df_news[df_news[\"page\"] == x]\n",
                "            print(\"        %s\" % row[\"title\"].values[0])\n",
                "\n",
                "        print(\"     Recommended:\")\n",
                "        \n",
                "        for x in top_items[:5]:\n",
                "            row = df_news[df_news[\"page\"] == x]\n",
                "            print(\"        %s\" % row[\"title\"].values[0])\n",
                "            print(x)\n",
                "        \n",
                "sample_recommendation(model, train_interactions,df_news, [26364]) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Top 5 items for new users: ['Quem é Giovanni Quintella, anestesista preso em flagrante por estuprar grávida no parto; ele atuou em pelo menos 10 hospitais', 'Casa abandonada em Higienópolis: Entenda o caso da mulher que vive em mansão de SP', 'Quem é Sabine Boghici, presa por golpe milionário contra a mãe e herdeira de um dos maiores colecionadores de arte do país', 'Jovem vai para a UTI após ser agredida e jogada em viela no litoral de SP', \"Integrante do 'Sexteto', Derico chora e lamenta morte de Jô Soares: 'Foi uma espécie de pai. Me ensinou tudo'\"]\n"
                    ]
                }
            ],
            "source": [
                "# Predict scores for all users\n",
                "num_users = interactions.shape[0]\n",
                "item_ids = np.arange(interactions.shape[1])\n",
                "\n",
                "# Predict scores for all users and average them\n",
                "average_scores = np.zeros_like(item_ids, dtype=float)\n",
                "for user_id in range(num_users):\n",
                "    average_scores += model.predict(user_id, item_ids)\n",
                "\n",
                "average_scores /= num_users\n",
                "\n",
                "# Recommend top-N items with the highest average scores\n",
                "top_n = 5\n",
                "recommended_items = np.vectorize(hash_dict.get)(np.argsort(-average_scores))[:top_n]\n",
                "recommended_items_name = []\n",
                "for i in recommended_items:\n",
                "    recommended_items_name.append(df_news[df_news[\"page\"] == i][\"title\"].values[0])\n",
                "print(f\"Top {top_n} items for new users: {recommended_items_name}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to lightfm_model.pkl\n",
                        "Model loaded successfully\n",
                        "User 4\n",
                        "     Known positives:\n",
                        "        Lista de concursos públicos e vagas de emprego - G1 Economia\n",
                        "     Recommended:\n",
                        "        Casa abandonada em Higienópolis: Entenda o caso da mulher que vive em mansão de SP\n",
                        "        Jovem é baleado, perde rim e hospital entrega órgão à família em saco plástico na Bahia\n",
                        "        Jovem vai para a UTI após ser agredida e jogada em viela no litoral de SP\n",
                        "        Quem é Giovanni Quintella, anestesista preso em flagrante por estuprar grávida no parto; ele atuou em pelo menos 10 hospitais\n",
                        "        Quem é Jorge Guaranho, apoiador de Bolsonaro que matou petista em Foz do Iguaçu\n",
                        "User 25\n",
                        "     Known positives:\n",
                        "        Quem é Sabine Boghici, presa por golpe milionário contra a mãe e herdeira de um dos maiores colecionadores de arte do país\n",
                        "        Filha é presa por golpe estimado em R$ 725 milhões contra a mãe; quadros renomados roubados foram recuperados\n",
                        "        Polícia prende cônsul alemão por suspeita na morte do marido no Rio; homem tinha lesões no corpo e na cabeça\n",
                        "     Recommended:\n",
                        "        Adolescente de 12 anos vítima de estupro coletivo na BA saiu da escola após 'virar chacota' entre os suspeitos, diz pai da jovem\n",
                        "        Jornal Nacional entrevistará candidatos à Presidência da República\n",
                        "        \n",
                        "Golpe em idosa: ‘Mata essa velha!’, mandou Rosa para Sabine em ligação, diz delegado\n",
                        "        Mãe descobre paradeiro de filha desaparecida por 36 anos em conversa com vizinho no litoral de SP \n",
                        "        VÍDEO: Tayara Andreza diz que teve de interromper show por não 'mandar alô' para prefeito de Tracunhaém\n",
                        "User 450\n",
                        "     Known positives:\n",
                        "        Quem é Sabine Boghici, presa por golpe milionário contra a mãe e herdeira de um dos maiores colecionadores de arte do país\n",
                        "        Menina de 9 anos grava áudio em que idoso confessa abuso sexual: 'minha mulherzinha'\n",
                        "        Vídeo mostra menina de 10 anos correndo após sair de padaria antes de desaparecer e ser achada morta\n",
                        "     Recommended:\n",
                        "        Jovem é baleado, perde rim e hospital entrega órgão à família em saco plástico na Bahia\n",
                        "        Giovanna Ewbank diz que filhos foram vítimas de racismo em Portugal\n",
                        "        Casa em que Hebe passava férias no Litoral de SP é colocada à venda por R$ 18 milhões\n",
                        "        Anestesista é investigado por 6 possíveis estupros: 'Tudo indica que era um criminoso em série', diz delegada\n",
                        "        Diácono é preso suspeito de estuprar jovem de 15 anos que namorava com filho dele no interior do AC\n"
                    ]
                }
            ],
            "source": [
                "import pickle\n",
                "\n",
                "with open('lightfm_model.pkl', 'wb') as f:\n",
                "    pickle.dump(model, f)\n",
                "print(\"Model saved to lightfm_model.pkl\")\n",
                "\n",
                "# Step 2: Load the model\n",
                "with open('lightfm_model.pkl', 'rb') as f:\n",
                "    loaded_model = pickle.load(f)\n",
                "print(\"Model loaded successfully\")\n",
                "\n",
                "sample_recommendation(loaded_model, train_interactions, df_news, [4, 25, 450]) "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
