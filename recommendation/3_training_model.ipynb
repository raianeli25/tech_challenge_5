{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model recommendation with lighfm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import itertools\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import scipy\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from lightfm import LightFM\n",
                "from lightfm.data import Dataset\n",
                "from lightfm.evaluation import precision_at_k, recall_at_k\n",
                "from lightfm.cross_validation import random_train_test_split\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from lightfm import cross_validation\n",
                "import scipy.sparse as sp\n",
                "from scipy import sparse"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Defining variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "with open('config.json', 'r') as f:\n",
                "    config = json.load(f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "\n",
                "TEST_PERCENTAGE = 0.20\n",
                "LEARNING_RATE = 0.1\n",
                "NUM_EPOCHS = 80\n",
                "NUM_COMPONENTS = 60\n",
                "NUM_THREADS = 4\n",
                "ALPHA_REG_L2 = 1e-3\n",
                "MAX_SAMPLED = 10\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Retrieve data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dtype_df_train_score = {\n",
                "\"userId\" : 'string',\n",
                "\"userType\" : 'category',\n",
                "\"history\" : 'string',\n",
                "\"score\" : 'Float32'\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# df_ratings = pd.read_csv(config[\"DF_TRAIN_SCORES\"], dtype=dtype_df_train_score)\n",
                "df_ratings = pd.read_csv(config[\"DF_TRAIN_SCORES\"], dtype=dtype_df_train_score, nrows=500000)\n",
                "df_ratings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_ratings.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
                "df_ratings.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_ratings.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dtype_df_items = {\n",
                "\"page\" : 'string',\n",
                "\"url\" : 'string',\n",
                "\"issued\" : 'string',\n",
                "\"modified\" : 'string',\n",
                "\"title\" : 'string',\n",
                "\"body\" : 'string',\n",
                "\"caption\" : 'string',\n",
                "\"age_in_days\" : 'UInt32',\n",
                "\"age_exp\" : 'Float32',\n",
                "\"age_exp_normalized\" : 'Float32',\n",
                "\"ageCategories\" : 'category'\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_news = pd.read_csv(config[\"DF_ITEMS_FEATURE\"], dtype=dtype_df_items)\n",
                "df_news.drop(columns=[\"Unnamed: 0\"],inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_news.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_news.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_merged = pd.merge(df_ratings, df_news, left_on='history', right_on='page', how='left')\n",
                "df_merged.drop(columns=[\"page\"],inplace=True) # 'page' is the same as 'history'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_merged.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_merged.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "w_initial_score = 0.85\n",
                "w_age_norm = 1-w_initial_score\n",
                "df_merged[\"score_init\"] = df_merged[\"score\"]*w_initial_score + df_merged[\"age_exp_normalized\"]*w_age_norm\n",
                "df_merged[\"score_fn\"] = df_merged[\"score_init\"].apply(lambda x: np.power(x,0.33))\n",
                "df_merged[\"score_norm\"] = (df_merged[\"score_fn\"]-df_merged[\"score_fn\"].min())/(df_merged[\"score_fn\"].max()-df_merged[\"score_fn\"].min())\n",
                "df_merged[\"score_1_to_5\"] = df_merged[\"score_norm\"]*4+1\n",
                "df_merged[\"score_1_to_5_int\"] = df_merged[\"score_1_to_5\"].round(0).astype(\"UInt16\")\n",
                "df_merged.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "column_score_to_use = \"score_1_to_5\"\n",
                "df_merged = df_merged[[\"userId\",\"history\",\"userType\",column_score_to_use]]\n",
                "df_merged.rename(columns={column_score_to_use:\"score\"},inplace=True)\n",
                "\n",
                "df_merged.rename(columns={\"ageCategories\" : \"historyFreshnessNormalized\"},inplace=True)\n",
                "df_merged.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df_merged.head()\n",
                "df_merged.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_merged.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Prepare data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before fitting the LightFM model, we need to create an instance of `Dataset` which holds the interaction matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = Dataset()\n",
                "\n",
                "# Get unique values for users, items, and user features\n",
                "unique_users = df_merged[\"userId\"].unique()\n",
                "unique_items = df_merged[\"history\"].unique()\n",
                "unique_user_features = df_merged[\"userType\"].unique().tolist()\n",
                "\n",
                "# Fit dataset with users, items, and user feature names\n",
                "dataset.fit(\n",
                "    users=unique_users,\n",
                "    items=unique_items,\n",
                "    user_features=unique_user_features  # Register user features\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(interactions, weights) = dataset.build_interactions([\n",
                "    (row.userId, row.history, row.score) \n",
                "    for _, row in df_merged.iterrows()\n",
                "])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "user_features_list = [\n",
                "    (row.userId, [row.userType])  \n",
                "    for _, row in df_merged.iterrows()\n",
                "]\n",
                "\n",
                "user_features = dataset.build_user_features(user_features_list)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LightLM works slightly differently compared to other packages as it expects the train and test sets to have same dimension. Therefore the conventional train test split will not work.\n",
                "\n",
                "The package has included the `cross_validation.random_train_test_split` method to split the interaction data and splits it into two disjoint training and test sets. \n",
                "\n",
                "However, note that **it does not validate the interactions in the test set to guarantee all items and users have historical interactions in the training set**. Therefore this may result into a partial cold-start problem in the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split train and test sets (80/20 split)\n",
                "train, test = cross_validation.random_train_test_split(interactions, test_percentage=TEST_PERCENTAGE, random_state=SEED)\n",
                "train_weights, test_weights  = cross_validation.random_train_test_split(weights, test_percentage=TEST_PERCENTAGE, random_state=SEED)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Double check the size of both the train and test sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Shape of train interactions: {train.shape}\")\n",
                "print(f\"Shape of test interactions: {test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Shape of train interactions: {train_weights.shape}\")\n",
                "print(f\"Shape of test interactions: {test_weights.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fit the LightFM model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this notebook, the LightFM model will be using the weighted Approximate-Rank Pairwise (WARP) as the loss. Further explanation on the topic can be found [here](https://making.lyst.com/lightfm/docs/examples/warp_loss.html#learning-to-rank-using-the-warp-loss).\n",
                "\n",
                "\n",
                "In general, it maximises the rank of positive examples by repeatedly sampling negative examples until a rank violation has been located. This approach is recommended when only positive interactions are present."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The LightFM model can be fitted with the following code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "model = LightFM(no_components=NUM_COMPONENTS,loss=\"warp\",learning_rate=LEARNING_RATE,user_alpha=ALPHA_REG_L2,max_sampled=MAX_SAMPLED,random_state=np.random.RandomState(SEED))  # Weighted Approximate-Rank Pairwise (WARP) loss\n",
                "model.fit(train, sample_weight=train_weights, epochs=NUM_EPOCHS, num_threads=NUM_THREADS, user_features=user_features)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Evaluate model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the evaluation routines\n",
                "from lightfm.evaluation import auc_score\n",
                "\n",
                "# Compute evaluation metrics\n",
                "auc_train = auc_score(model, train, user_features=user_features, num_threads=NUM_THREADS).mean()\n",
                "auc_test = auc_score(model, test, train_interactions=train, user_features=user_features, num_threads=NUM_THREADS).mean()\n",
                "\n",
                "# Print evaluation results\n",
                "print(f\"AUC test Score: {auc_test:.4f}\")\n",
                "print(f\"AUC train Score: {auc_train:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Measure how well it did in the Test period\n",
                "# for metric in [precision_at_k, recall_at_k]:\n",
                "#     # Get the precision and recall for Train and Test\n",
                "#     for data, name in [(train, \"Train\"), (test, \"Test \")]:\n",
                "#         print(f\"{name} {metric.__name__}: %.2f\" % \n",
                "#               metric(model,\n",
                "#                          data, \n",
                "#                          k=10).mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Save pkls to serve model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "user_id_map, user_feature_map, item_id_map, item_feature_map = dataset.mapping()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "item_id_map_reverse = {v: k for k, v in item_id_map.items()}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "interactions_shape = interactions.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "pickle.dump(model, open('artifacts/lightfm_model.pkl', 'wb'))\n",
                "pickle.dump(user_id_map, open('artifacts/user_id_map.pkl', 'wb'))\n",
                "pickle.dump(item_id_map_reverse, open('artifacts/item_id_map_reverse.pkl', 'wb'))\n",
                "pickle.dump(user_feature_map, open('artifacts/user_feature_map.pkl', 'wb'))\n",
                "pickle.dump(interactions_shape, open('artifacts/interactions_shape.pkl', 'wb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "import numpy as np\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loaded_model = pickle.load(open('artifacts/lightfm_model.pkl', 'rb'))\n",
                "loaded_user_id_map = pickle.load(open('artifacts/user_id_map.pkl', 'rb'))\n",
                "loaded_item_id_map_reverse = pickle.load(open('artifacts/item_id_map_reverse.pkl', 'rb'))\n",
                "loaded_user_feature_map = pickle.load(open('artifacts/user_feature_map.pkl', 'rb'))\n",
                "loaded_interactions_shape = pickle.load(open('artifacts/interactions_shape.pkl', 'rb'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interaction and Weight Matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(weights[:5,:5].todense())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Scored Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Force lightFM to create predictions for all users and all items\n",
                "# import numpy as np\n",
                "# n_items = 5\n",
                "# n_users = 7\n",
                "\n",
                "# print([np.full((n_items, ), 1), np.full((n_items, ), 2)])\n",
                "# print(np.concatenate([np.full((n_items, ), 1), np.full((n_items, ), 2)]))\n",
                "# print(np.arange((n_items)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# n_items = 5\n",
                "# n_users = 7\n",
                "\n",
                "# scoring_user_ids = np.concatenate([np.full((n_items, ), i) for i in range(n_users)]) # repeat user ID for number of prods \n",
                "# scoring_item_ids = np.concatenate([np.arange(n_items) for i in range(n_users)]) # repeat entire range of item IDs x number of user\n",
                "# print(scoring_user_ids)\n",
                "# print(scoring_item_ids)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loaded_n_users, loaded_n_items = loaded_interactions_shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "items_idx_to_score = np.arange(loaded_n_items)\n",
                "scores_matrix_dtype = np.int16\n",
                "\n",
                "scores = np.zeros((loaded_n_users,loaded_n_items),dtype=scores_matrix_dtype)\n",
                "\n",
                "for user in range(1000):\n",
                "    scores[user,] = loaded_model.predict(user_ids = user, item_ids = items_idx_to_score)\n",
                "    if user%1000 == 0:\n",
                "        print(f\"iteration = {user}\")\n",
                "\n",
                "# scores = model.predict(user_ids = scoring_user_ids, \n",
                "#                                      item_ids = scoring_item_ids)\n",
                "# scores = scores.reshape(-1, n_items) # get 1 row per user\n",
                "recommendations = pd.DataFrame(scores).astype(\"Int16\")\n",
                "recommendations.shape\n",
                "\n",
                "# Have a look at the predicted scores for the first 5 users and first 5 items\n",
                "recommendations.iloc[:5,:5] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>0</th>\n",
                            "      <th>1</th>\n",
                            "      <th>2</th>\n",
                            "      <th>3</th>\n",
                            "      <th>4</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>10</td>\n",
                            "      <td>13</td>\n",
                            "      <td>4</td>\n",
                            "      <td>2</td>\n",
                            "      <td>-26</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>7</td>\n",
                            "      <td>6</td>\n",
                            "      <td>9</td>\n",
                            "      <td>75</td>\n",
                            "      <td>-29</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1</td>\n",
                            "      <td>37</td>\n",
                            "      <td>0</td>\n",
                            "      <td>88</td>\n",
                            "      <td>84</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>15</td>\n",
                            "      <td>-47</td>\n",
                            "      <td>16</td>\n",
                            "      <td>324</td>\n",
                            "      <td>-189</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>-8</td>\n",
                            "      <td>34</td>\n",
                            "      <td>80</td>\n",
                            "      <td>-254</td>\n",
                            "      <td>673</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    0    1   2     3     4\n",
                            "0  10   13   4     2   -26\n",
                            "1   7    6   9    75   -29\n",
                            "2   1   37   0    88    84\n",
                            "3  15  -47  16   324  -189\n",
                            "4  -8   34  80  -254   673"
                        ]
                    },
                    "execution_count": 57,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "recommendations.iloc[:5,:5] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "recommendations.min().describe()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "recommendations.max().describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "recommendations.mean().describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Make predictions to known and unknowm on same recommendation function with pkls"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_newuser_input(user_feature_map, user_feature_list):\n",
                "  normalised_val = 1.0 \n",
                "  target_indices = []\n",
                "  for feature in user_feature_list:\n",
                "    try:\n",
                "        target_indices.append(user_feature_map[feature])\n",
                "    except KeyError:\n",
                "        print(\"new user feature encountered '{}'\".format(feature))\n",
                "        pass\n",
                "  #print(\"target indices: {}\".format(target_indices))\n",
                "  new_user_features = np.zeros(len(user_feature_map.keys()))\n",
                "  for i in target_indices:\n",
                "    new_user_features[i] = normalised_val\n",
                "  new_user_features = sparse.csr_matrix(new_user_features)\n",
                "  return(new_user_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample_recommendation(user_hash,df_news,user_feature_list,item_id_map_reverse,user_feature_map,user_id_map,model):\n",
                "    try:\n",
                "        user_x = user_id_map[user_hash]\n",
                "        scores = model.predict(user_x, np.arange(loaded_n_items)) # means predict for all\n",
                "    except:\n",
                "        new_user_features = format_newuser_input(user_feature_map, user_feature_list)\n",
                "        scores = model.predict(0, np.arange(loaded_n_items), user_features=new_user_features)\n",
                "    \n",
                "    top_5_indices = np.argsort(-scores)[:5]  # Sort scores in descending order and take the top 5\n",
                "    top_5_items = [item_id_map_reverse[i] for i in top_5_indices]\n",
                "\n",
                "    print(\"Top 5 recommended items:\")\n",
                "\n",
                "    for x in top_5_items:\n",
                "        row = df_news[df_news[\"page\"] == x]\n",
                "        print(\"        %s\" % row[\"page\"].values[0])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "new user feature encountered 'userType:Logged'\n",
                        "Top 5 recommended items:\n",
                        "        d2593c3d-2347-40d9-948c-b6065e8459a9\n",
                        "        f6b5d170-48b9-4f8e-88d4-c84b6668f3bd\n",
                        "        1f32787b-de2b-49be-8c20-ddaeae34cc22\n",
                        "        bf257382-74fb-4392-ad6a-143240e39f81\n",
                        "        f0a78e58-ec7e-494c-9462-fbd6446a9a89\n"
                    ]
                }
            ],
            "source": [
                "# predict for known user\n",
                "user_feature_list = ['userType:Logged']\n",
                "user_hash = '5f5e17781fc2ec0ddcfb2e9356e61c5d3d4b0b3c8fabd20917feb9e807463856'\n",
                "sample_recommendation(user_hash,df_news,user_feature_list,loaded_item_id_map_reverse,loaded_user_feature_map,loaded_user_id_map,loaded_model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "new user feature encountered 'userType:Non-Logged'\n",
                        "Top 5 recommended items:\n",
                        "        d2593c3d-2347-40d9-948c-b6065e8459a9\n",
                        "        f6b5d170-48b9-4f8e-88d4-c84b6668f3bd\n",
                        "        1f32787b-de2b-49be-8c20-ddaeae34cc22\n",
                        "        bf257382-74fb-4392-ad6a-143240e39f81\n",
                        "        f0a78e58-ec7e-494c-9462-fbd6446a9a89\n"
                    ]
                }
            ],
            "source": [
                "# predict for unknown user\n",
                "user_feature_list = ['userType:Non-Logged']\n",
                "user_hash = ''\n",
                "sample_recommendation(user_hash,df_news,user_feature_list,loaded_item_id_map_reverse,loaded_user_feature_map,loaded_user_id_map,loaded_model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'fbb963d61eb8149e7f43b1bd905457ba5e106a830ddc27288434101e7252ef57'"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_merged.loc[0,'userId']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Non-Logged'"
                        ]
                    },
                    "execution_count": 54,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_merged.loc[0,'userType']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Top 5 recommended items:\n",
                        "        c22f9540-546c-499c-8c8a-4fa281ed7377\n",
                        "        248ff2c6-fb06-4429-bdae-03f14f8f3378\n",
                        "        01c814ce-12aa-42a3-9eec-a5e2cf9a522b\n",
                        "        fe553b8c-4e9d-4c05-8e80-5fd7ddd7dacc\n",
                        "        a76034ac-8696-4f17-8d72-91d8ae09dd83\n"
                    ]
                }
            ],
            "source": [
                "user_feature_list = ['userType:Non-Logged']\n",
                "user_hash = 'fbb963d61eb8149e7f43b1bd905457ba5e106a830ddc27288434101e7252ef57'\n",
                "sample_recommendation(user_hash,df_news,user_feature_list,loaded_item_id_map_reverse,loaded_user_feature_map,loaded_user_id_map,loaded_model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 56,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "user_id_map[\"fbb963d61eb8149e7f43b1bd905457ba5e106a830ddc27288434101e7252ef57\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'17f1083e6079b0f28f7820a6803583d1c1b405c0718b11a18d30b1620f643b23'"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_merged.loc[2,'userId']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Non-Logged'"
                        ]
                    },
                    "execution_count": 59,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_merged.loc[2,'userType']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_recommendation(user_hash,df_news,user_feature_list,loaded_item_id_map_reverse,loaded_user_feature_map,loaded_user_id_map,loaded_model)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
